{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train_vectorized, y_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "plot_confusion_matrix(nb, X_train_vectorized, y_train, ax=ax, cmap=\"cividis\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the coefficient and sort them\n",
    "coef = nb.coef_[0]\n",
    "top_positive_coefficients = np.argsort(coef)[:10]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "colors = ['red' if c < 0 else 'blue' for c in coef[top_positive_coefficients]]\n",
    "plt.barh(np.arange(len(top_positive_coefficients)), coef[top_positive_coefficients], color=colors)\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "plt.yticks(np.arange(len(top_positive_coefficients)), feature_names[top_positive_coefficients], rotation=0, ha='right')\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Most Predictive Features and Associated Coefficients - Naive Bayes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def plot_feature_importance(model, X, y):\n",
    "    y = np.array(y)  # Convert y to numpy array\n",
    "    target_names = np.unique(y)\n",
    "    n_targets = len(target_names)\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feat_imp_all = model.feature_importances_.reshape(n_targets, -1)\n",
    "    else:\n",
    "        feat_imp_all = np.log(np.abs(model.coef_))\n",
    "    \n",
    "    f1_scores = []\n",
    "    for t in range(n_targets):\n",
    "        X_subset = X[np.where(y == target_names[t])]\n",
    "        y_subset = y[np.where(y == target_names[t])]\n",
    "        y_pred_subset = model.predict(X_subset)\n",
    "        f1_scores.append(f1_score(y_subset, y_pred_subset, average='weighted'))\n",
    "    \n",
    "    f1_scores = np.array(f1_scores)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    colors = ['r', 'g', 'b']\n",
    "    all_sorted_idx = []\n",
    "    \n",
    "    for t, target_name in enumerate(target_names):\n",
    "        feat_imp = 100.0 * (feat_imp_all[t] * f1_scores[t] / feat_imp_all[t].max())\n",
    "        sorted_idx = np.argsort(feat_imp)[::-1][:10]\n",
    "        all_sorted_idx.extend(sorted_idx)\n",
    "\n",
    "        plt.bar(np.arange(t * 10, t * 10 + 10), feat_imp[sorted_idx], color=colors[t], alpha=.7)\n",
    "\n",
    "    plt.xticks(np.arange(30), np.array(vectorizer.get_feature_names())[all_sorted_idx], rotation=90)\n",
    "    plt.title(\"Top 10 Feature Importances for Each Target (weighted by f1_score)\")\n",
    "    plt.legend(target_names)\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance(nb, X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for feature importance\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train_vectorized, y_train)\n",
    "\n",
    "feature_importances = nb.coef_[0]\n",
    "\n",
    "feature_importances_sorted = sorted(zip(feature_importances, vectorizer.get_feature_names()), reverse=True)\n",
    "\n",
    "N = 20\n",
    "top_features = [f[1] for f in feature_importances_sorted[:N]]\n",
    "top_importances = [f[0] for f in feature_importances_sorted[:N]]\n",
    "\n",
    "plt.barh(np.arange(len(top_features)), top_importances)\n",
    "plt.yticks(np.arange(len(top_features)), top_features)\n",
    "plt.title('Top {} Most Important Features'.format(N))\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer, plot_confusion_matrix\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC, SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from code.cleaner import preprocess\n",
    "from code.viz import word_plot\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = pd.read_csv('./data/judge-1377884607_tweet_product_company.csv',encoding='ISO-8859-1')\n",
    "sentiments.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments.rename(columns={\n",
    "    'emotion_in_tweet_is_directed_at':'product',\n",
    "    'is_there_an_emotion_directed_at_a_brand_or_product':'sentiment'\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments.dropna(subset=['tweet_text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reclassify = sentiments[sentiments['sentiment'] == \"I can't tell\"]\n",
    "sentiments = sentiments[sentiments['sentiment'] != \"I can't tell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "#specific_words = ['@mention','link','sxsw','#sxsw','@sxsw']\n",
    "specific_words = ['@mention','link','sxsw','#sxsw','@sxsw',\n",
    "                  'google','iphone', 'ipad', 'android', 'app',\n",
    "                  'apple', 'rt', 'quot', 'store', 'new', 'austin'\n",
    "                  'circle'\n",
    "                 ]\n",
    "# ^^ these are the original extended stop words from initial data\n",
    "# discovery and knowledge \n",
    "discovered_words = [\n",
    "    'google','iphone', 'ipad', 'android', 'app',\n",
    "    'apple', 'rt', 'quot', 'store', 'new', 'austin'\n",
    "    ]\n",
    "specific_words.extend(discovered_words)\n",
    "sw.extend(specific_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    " & \\text{Negative} & \\text{Neutral} & \\text{Positive} \\\\\n",
    "\\text{Negative} & \\text{True-Neg} & \\text{FNeu-Neg} & \\text{FP-Neg} \\\\\n",
    "\\text{Neutral} & \\text{False-Neg-Neu} & \\text{True-Neu} & \\text{False-P-Neu} \\\\\n",
    "\\text{Positive} & \\text{False-Neg} & \\text{False-Neu-Pos} & \\text{TP} \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments['tokenized'], sentiments['tokens'] = \\\n",
    "    preprocess(sentiments['tweet_text'],sw=sw,ret_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = sentiments[['tokenized','tokens']]\n",
    "y2 = sentiments['sentiment']\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = \\\n",
    "    train_test_split(X2,y2,\n",
    "        test_size=0.2,\n",
    "        stratify=y2,random_state=13)\n",
    "\n",
    "train = X_train2.merge(\n",
    "    y_train,left_index=True,right_index=True\n",
    "    )\n",
    "test = X_test2.merge(\n",
    "    y_test,left_index=True,right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7148"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    4310.4\n",
       "Positive emotion                      2382.4\n",
       "Negative emotion                       456.0\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments['sentiment'].value_counts()*.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sentiments['tokenized']\n",
    "y = sentiments['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X,y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.4, min_df=20, ngram_range=[1, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=[1,3],max_df=0.4,min_df=20)\n",
    "\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_length = len(train[train['sentiment'] == 'No emotion toward brand or product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_dict = {\"No emotion toward brand or product\": majority_length,\n",
    "           \"Positive emotion\": majority_length*0.5,\n",
    "           \"Negative emotion\": majority_length*0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sm', SMOTE(random_state=13)), ('svec', SVC(random_state=13))])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svec = imbPipeline(steps=[\n",
    "    ('sm', SMOTE(random_state=13)),\n",
    "    ('svec', SVC(random_state=13))\n",
    "])\n",
    "\n",
    "svec.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84405458, 0.9141656 , 0.86169535])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = svec.predict(X_train_vectorized)\n",
    "f1_score(y_train, preds, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3877551 , 0.75332742, 0.57193606])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = svec.predict(X_test_vectorized)\n",
    "f1_score(y_test, preds, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
